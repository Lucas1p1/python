{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bd1b5bc-7e65-4222-98ad-666547964cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras_preprocessing.image import load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout,Flatten, MaxPooling2D\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6777b136-c49d-4669-b46e-f8498fd7e976",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'images/train'\n",
    "TEST_DIR = 'images/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "941dbce2-c148-4df5-9eea-4529c54b6f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def createdataframe(dir):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    for label in os.listdir(dir):\n",
    "        for imagename in os.listdir(os.path.join(dir, label)):\n",
    "            image_paths.append(os.path.join(dir, label, imagename))\n",
    "            labels.append(label)\n",
    "        print(label, \"completed\")\n",
    "    return image_paths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26f22d21-c565-4a69-9c67-c484841e8925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry completed\n",
      "disgust completed\n",
      "fear completed\n",
      "happy completed\n",
      "neutral completed\n",
      "sad completed\n",
      "surprise completed\n"
     ]
    }
   ],
   "source": [
    "train = pd.DataFrame()\n",
    "train['image'], train['label']= createdataframe(TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9b627dd-3d3e-41c8-944a-3adfc887b8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                image     label\n",
      "0            images/train\\angry\\0.jpg     angry\n",
      "1            images/train\\angry\\1.jpg     angry\n",
      "2           images/train\\angry\\10.jpg     angry\n",
      "3        images/train\\angry\\10002.jpg     angry\n",
      "4        images/train\\angry\\10016.jpg     angry\n",
      "...                               ...       ...\n",
      "28816  images/train\\surprise\\9969.jpg  surprise\n",
      "28817  images/train\\surprise\\9985.jpg  surprise\n",
      "28818  images/train\\surprise\\9990.jpg  surprise\n",
      "28819  images/train\\surprise\\9992.jpg  surprise\n",
      "28820  images/train\\surprise\\9996.jpg  surprise\n",
      "\n",
      "[28821 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc025fc8-5d93-40f3-a964-ade013c18338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry completed\n",
      "disgust completed\n",
      "fear completed\n",
      "happy completed\n",
      "neutral completed\n",
      "sad completed\n",
      "surprise completed\n"
     ]
    }
   ],
   "source": [
    "test = pd.DataFrame()\n",
    "test['image'], test['label']= createdataframe(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fa4a549-4278-4ff8-b5ec-e90e14ce03dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              image     label\n",
      "0       images/test\\angry\\10052.jpg     angry\n",
      "1       images/test\\angry\\10065.jpg     angry\n",
      "2       images/test\\angry\\10079.jpg     angry\n",
      "3       images/test\\angry\\10095.jpg     angry\n",
      "4       images/test\\angry\\10121.jpg     angry\n",
      "...                             ...       ...\n",
      "7061  images/test\\surprise\\9806.jpg  surprise\n",
      "7062  images/test\\surprise\\9830.jpg  surprise\n",
      "7063  images/test\\surprise\\9853.jpg  surprise\n",
      "7064  images/test\\surprise\\9878.jpg  surprise\n",
      "7065   images/test\\surprise\\993.jpg  surprise\n",
      "\n",
      "[7066 rows x 2 columns]\n",
      "0         images/test\\angry\\10052.jpg\n",
      "1         images/test\\angry\\10065.jpg\n",
      "2         images/test\\angry\\10079.jpg\n",
      "3         images/test\\angry\\10095.jpg\n",
      "4         images/test\\angry\\10121.jpg\n",
      "                    ...              \n",
      "7061    images/test\\surprise\\9806.jpg\n",
      "7062    images/test\\surprise\\9830.jpg\n",
      "7063    images/test\\surprise\\9853.jpg\n",
      "7064    images/test\\surprise\\9878.jpg\n",
      "7065     images/test\\surprise\\993.jpg\n",
      "Name: image, Length: 7066, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(test)\n",
    "print(test['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "214aa3f7-7751-4929-96b0-8424e2cdc313",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b97dcaa-31ac-4a12-a7d2-7246b1e72d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def extract_features(images):\n",
    "    features = []  # Define features before using it\n",
    "    for image in tqdm(images):\n",
    "        img = load_img(image, grayscale=True)\n",
    "        img = np.array(img)\n",
    "        features.append(img)\n",
    "    \n",
    "    features = np.array(features)\n",
    "    features = features.reshape(len(features), 48, 48, 1)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a9fd34b-3bc6-4a98-a847-b6e04e556d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010003805160522461,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 11,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 28821,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36a56bdc86d54caab0074ba3f8abb280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28821 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lucifer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras_preprocessing\\image\\utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    }
   ],
   "source": [
    "train_features = extract_features(train['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41b60e3c-109d-4d12-8643-4ea3cbe05f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011722803115844727,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 11,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 7066,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "765b03b543304834a690990f27291a9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7066 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_features = extract_features(test['image'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb7a569c-7625-4e19-9f96-bc3103e24b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_features/255.0\n",
    "x_test = test_features/255.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5991446-a1a8-467e-bcc9-7275c64e78a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f45621e-a29f-4bc5-afbf-e659f524e249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65f8e167-06b2-43c0-84a8-5794f853f34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = le.transform(train['label'])\n",
    "y_test = le.transform(test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47cb7613-83c4-4e50-8c57-fce9aaa1e464",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train,num_classes = 7)\n",
    "y_test = to_categorical(y_test,num_classes = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0166eebd-28cc-4782-80ef-cff2200fa8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#convolutional layers\n",
    "model.add(Conv2D(128, kernel_size=(3,3),activation='relu',input_shape=(48,48,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4 ))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "#fully connected layers\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256, activation='relu'))          \n",
    "model.add(Dropout(0.3))\n",
    "#Output Layer\n",
    "model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f75e8b7-dc9f-4e6e-afaf-1b605250425a",
   "metadata": {},
   "outputs": [],
   "source": [
    " model.compile(optimizer= 'adam', loss = 'categorical_crossentropy',metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da688060-ca4e-4018-99af-5d8469e3d09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "226/226 [==============================] - 418s 2s/step - loss: 1.8222 - accuracy: 0.2449 - val_loss: 1.8025 - val_accuracy: 0.2472\n",
      "Epoch 2/15\n",
      "226/226 [==============================] - 553s 2s/step - loss: 1.7798 - accuracy: 0.2567 - val_loss: 1.7013 - val_accuracy: 0.3098\n",
      "Epoch 3/15\n",
      "226/226 [==============================] - 546s 2s/step - loss: 1.6743 - accuracy: 0.3183 - val_loss: 1.5648 - val_accuracy: 0.4029\n",
      "Epoch 4/15\n",
      "226/226 [==============================] - 479s 2s/step - loss: 1.5653 - accuracy: 0.3824 - val_loss: 1.4372 - val_accuracy: 0.4546\n",
      "Epoch 5/15\n",
      "226/226 [==============================] - 489s 2s/step - loss: 1.4882 - accuracy: 0.4199 - val_loss: 1.3749 - val_accuracy: 0.4754\n",
      "Epoch 6/15\n",
      "226/226 [==============================] - 572s 3s/step - loss: 1.4421 - accuracy: 0.4424 - val_loss: 1.3210 - val_accuracy: 0.4948\n",
      "Epoch 7/15\n",
      "226/226 [==============================] - 516s 2s/step - loss: 1.4067 - accuracy: 0.4571 - val_loss: 1.2891 - val_accuracy: 0.5069\n",
      "Epoch 8/15\n",
      "226/226 [==============================] - 467s 2s/step - loss: 1.3902 - accuracy: 0.4648 - val_loss: 1.2863 - val_accuracy: 0.5218\n",
      "Epoch 9/15\n",
      "226/226 [==============================] - 483s 2s/step - loss: 1.3632 - accuracy: 0.4768 - val_loss: 1.2456 - val_accuracy: 0.5265\n",
      "Epoch 10/15\n",
      "226/226 [==============================] - 481s 2s/step - loss: 1.3484 - accuracy: 0.4820 - val_loss: 1.2625 - val_accuracy: 0.5174\n",
      "Epoch 11/15\n",
      "226/226 [==============================] - 411s 2s/step - loss: 1.3373 - accuracy: 0.4848 - val_loss: 1.2623 - val_accuracy: 0.5164\n",
      "Epoch 12/15\n",
      "226/226 [==============================] - 465s 2s/step - loss: 1.3118 - accuracy: 0.4954 - val_loss: 1.2142 - val_accuracy: 0.5379\n",
      "Epoch 13/15\n",
      "226/226 [==============================] - 442s 2s/step - loss: 1.3017 - accuracy: 0.5013 - val_loss: 1.1870 - val_accuracy: 0.5529\n",
      "Epoch 14/15\n",
      "226/226 [==============================] - 428s 2s/step - loss: 1.2962 - accuracy: 0.5050 - val_loss: 1.1721 - val_accuracy: 0.5534\n",
      "Epoch 15/15\n",
      "226/226 [==============================] - 2817s 13s/step - loss: 1.2756 - accuracy: 0.5092 - val_loss: 1.1874 - val_accuracy: 0.5509\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x25ffcaee610>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = x_train,y = y_train, batch_size = 128, epochs = 15, validation_data = (x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e3c3b44-f03c-4061-9571-3074079d72d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lucifer\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"emotiondetector.json\",'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save(\"emotiondetector.h5\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ab1b1d0-aea2-41ad-b77c-22174f9aa45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3c4cc20-16fb-481e-b296-2e43d2bace0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open(\"facialemotionmodel.json\", \"r\")\n",
    "model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(model_json)\n",
    "model.load_weights(\"facialemotionmodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2423ce38-f79f-4686-b29d-ce1c2d5c7cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ['angry','disgust','fear','happy','neutral','sad','surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1272019e-adbc-4106-8828-220201a82c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original image is of angry\n",
      "Input shape: (1, 48, 48, 1)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "Model prediction is angry\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "def ef(image_path):\n",
    "    img = image.load_img(image_path, grayscale=True, target_size=(48, 48))\n",
    "    feature = np.array(img)\n",
    "    feature = feature.reshape(1, 48, 48, 1)  # Add batch dimension and channel\n",
    "    return feature / 255.0  # Normalize the pixel values\n",
    "\n",
    "# Assuming 'model' is your trained model\n",
    "image_path = 'images/train/angry/22.jpg'\n",
    "print(\"Original image is of angry\")\n",
    "img = ef(image_path)\n",
    "\n",
    "# Check the shape of the input before passing it to the model\n",
    "print(\"Input shape:\", img.shape)\n",
    "\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"Model prediction is\", pred_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "905aab88-f75e-42ac-9430-8d97feb7f2b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original image is of angry\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'load_img'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages/train/angry/22.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moriginal image is of angry\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mef\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(img)\n\u001b[0;32m      5\u001b[0m pred_label \u001b[38;5;241m=\u001b[39m label[pred\u001b[38;5;241m.\u001b[39margmax()]\n",
      "Cell \u001b[1;32mIn[48], line 5\u001b[0m, in \u001b[0;36mef\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mef\u001b[39m(image_path):\n\u001b[1;32m----> 5\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_img\u001b[49m(image_path, grayscale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m))\n\u001b[0;32m      6\u001b[0m     feature \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(img)\n\u001b[0;32m      7\u001b[0m     feature \u001b[38;5;241m=\u001b[39m feature\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Add batch dimension and channel\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'load_img'"
     ]
    }
   ],
   "source": [
    "\n",
    "image = 'images/train/angry/22.jpg'\n",
    "print(\"original image is of angry\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is \",pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab1783ca-5541-49ff-822c-adfb35363a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf\n",
      "  Downloading tf-1.0.0.tar.gz (620 bytes)\n",
      "Building wheels for collected packages: tf\n",
      "  Building wheel for tf (setup.py): started\n",
      "  Building wheel for tf (setup.py): finished with status 'done'\n",
      "  Created wheel for tf: filename=tf-1.0.0-py3-none-any.whl size=1293 sha256=dcc067f8c24d6ab5bb056d44fd7f012472ae768aad4194166100a5a0a1da9173\n",
      "  Stored in directory: c:\\users\\lucifer\\appdata\\local\\pip\\cache\\wheels\\92\\d0\\89\\ab087968a762db2e1690a34d286cd41a3bd38ebeb3f99039d2\n",
      "Successfully built tf\n",
      "Installing collected packages: tf\n",
      "Successfully installed tf-1.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\lucifer\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "022c6be6-7197-433a-b24b-51ea95e1585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pit\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d97a6155-efd5-4267-b891-ca3006330687",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (841583769.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[55], line 5\u001b[1;36m\u001b[0m\n\u001b[1;33m    pred_label = label[pred.argmax()]\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "image = 'images/train/sad/42.jpg'\n",
    "print(\"original image is of sad\")\n",
    "img = ef(image)\n",
    "pred = (model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is \",pred_label)\n",
    "plt.imshow(img.reshape(48,48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b62e9c7a-4d9c-42e9-abd2-367eea8d2b13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Replace these with your actual y_true and y_pred values\n",
    "y_true = [1, 0, 1, 2, 1, 0, 1, 2, 2, 0]\n",
    "y_pred = [1, 0, 1, 2, 2, 0, 1, 2, 1, 0]\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot confusion matrix using seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5ef3f7-e1ef-4bbd-8af6-0dd302bd79bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
